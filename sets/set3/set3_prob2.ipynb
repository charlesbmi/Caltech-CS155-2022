{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "set3_prob2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlesincharge/Caltech-CS155-2022/blob/main/sets/set3/set3_prob2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF1crkj-DTKO"
      },
      "source": [
        "# Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNkW8PGKDTKW"
      },
      "source": [
        "Import statements and function to load data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yXh6KLlUDTKX"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "def load_data(filename, skiprows = 1):\n",
        "    \"\"\"\n",
        "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
        "    \n",
        "    Inputs:\n",
        "        filename: given as a string.\n",
        "        \n",
        "    Outputs:\n",
        "        Data contained in the file, returned as a numpy ndarray\n",
        "    \"\"\"\n",
        "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLrmxR3hDTKa"
      },
      "source": [
        "Load the data and divide it into training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yli92gNpDTKb"
      },
      "source": [
        "# The number 24 in the next line corresponds to the number of header lines\n",
        "X = load_data('https://raw.githubusercontent.com/charlesincharge/Caltech-CS155-2022/main/sets/set3/data/messidor_features.arff',24)\n",
        "\n",
        "data = X[:, :-1]\n",
        "diag = X[:, -1]\n",
        "\n",
        "train_size = 900\n",
        "\n",
        "train_data = data[0:train_size]\n",
        "train_label = diag[0:train_size]\n",
        "test_data = data[train_size:]\n",
        "test_label = diag[train_size:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcZCTQQRDTKb"
      },
      "source": [
        "## Problem 2A(i): Decision Trees with Minimum Leaf Size Stopping Criterion\n",
        "\n",
        "Note: If you chose to not do the EC please delete the corresponding cells. \n",
        "\n",
        "Fill in the two functions below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kt1r-5y8DTKd"
      },
      "source": [
        "def classification_err(y, real_y):\n",
        "    \"\"\"\n",
        "    This function returns the classification error between two equally-sized vectors of \n",
        "    labels; this is the fraction of samples for which the labels differ.\n",
        "    \n",
        "    Inputs:\n",
        "        y: (N, ) shaped array of predicted labels\n",
        "        real_y: (N, ) shaped array of true labels\n",
        "    Output:\n",
        "        Scalar classification error\n",
        "    \"\"\"\n",
        "    #==============================================\n",
        "    # TODO: Implement the classification_err function,\n",
        "    # based on the above instructions.\n",
        "    #==============================================    \n",
        "    pass\n",
        "\n",
        "def eval_tree_based_model_min_samples(clf, min_samples_leaf, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
        "    minimum leaf size parameters in the vector min_samples_leaf, using the given training and testing\n",
        "    data. It returns two vector, with the training and testing classification errors.\n",
        "    \n",
        "    Inputs:\n",
        "        clf: either a decision tree or random forest classifier object\n",
        "        min_samples_leaf: a (T, ) vector of all the min_samples_leaf stopping condition parameters \n",
        "                            to test, where T is the number of parameters to test\n",
        "        X_train: (N, D) matrix of training samples.\n",
        "        y_train: (N, ) vector of training labels.\n",
        "        X_test: (N, D) matrix of test samples\n",
        "        y_test: (N, ) vector of test labels\n",
        "    Output:\n",
        "        train_err: (T, ) vector of classification errors on the training data\n",
        "        test_err: (T, ) vector of classification errors on the test data\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # TODO: Implement the eval_tree_based_model_min_samples function,\n",
        "    # based on the above instructions.\n",
        "    #================================================================ \n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H5eWpq1tDTKd"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "min_samples_leaf = np.arange(1, 26)\n",
        "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_min_samples(clf, min_samples_leaf, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(min_samples_leaf, test_err, label='Testing error')\n",
        "plt.plot(min_samples_leaf, train_err, label='Training error')\n",
        "plt.xlabel('Minimum Node Size')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Decision Tree with Gini Impurity and Minimum Node Size')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at min_samples_leaf = %i' % min_samples_leaf[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_t441edDTKe"
      },
      "source": [
        "## Problem 2A(ii): Decision Trees with Maximum Depth Stopping Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3304HhiDTKg"
      },
      "source": [
        "Fill in the function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fmdPE5zaDTKg"
      },
      "source": [
        "def eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
        "    maximum tree depth parameters in the vector max_depth, using the given training and testing\n",
        "    data. It returns two vector, with the training and testing classification errors.\n",
        "    \n",
        "    Inputs:\n",
        "        clf: either a decision tree or random forest classifier object\n",
        "        max_depth: a (T, ) vector of all the max_depth stopping condition parameters \n",
        "                            to test, where T is the number of parameters to test\n",
        "        X_train: (N, D) matrix of training samples.\n",
        "        y_train: (N, ) vector of training labels.\n",
        "        X_test: (N, D) matrix of test samples\n",
        "        y_test: (N, ) vector of test labels\n",
        "    Output:\n",
        "        train_err: (T, ) vector of classification errors on the training data\n",
        "        test_err: (T, ) vector of classification errors on the test data\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # TODO: Implement the eval_tree_based_model_max_depth function,\n",
        "    # based on the above instructions.\n",
        "    #================================================================ \n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uVu4fiH5DTKi"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "max_depth = np.arange(2, 21)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(max_depth, test_err, label='Testing error')\n",
        "plt.plot(max_depth, train_err, label='Training error')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Decision Tree with Gini Impurity and Maximum Tree Depth')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at max_depth = %i' % max_depth[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHw7Gq-EDTKj"
      },
      "source": [
        "## Problem 2C(i): Random Forests with Minimum Leaf Size Stopping Criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yIpZMC3kDTKj"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "n_estimators = 1000\n",
        "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
        "\n",
        "min_samples_leaf = np.arange(1, 26)\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_min_samples(clf, min_samples_leaf, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(min_samples_leaf, test_err, label='Testing error')\n",
        "plt.plot(min_samples_leaf, train_err, label='Training error')\n",
        "plt.xlabel('Minimum Node Size')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Random Forest with Gini Impurity and Minimum Node Size')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at min_samples_leaf = %i' % min_samples_leaf[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q1SeXsZDTKj"
      },
      "source": [
        "## Problem 2C(ii): Random Forests with Maximum Depth Stopping Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LdM7YnCZDTKj"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
        "\n",
        "max_depth = np.arange(2, 21)\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(max_depth, test_err, label='Testing error')\n",
        "plt.plot(max_depth, train_err, label='Training error')\n",
        "plt.xlabel('Maximum Depth')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Random Forest with Gini Impurity and Maximum Depth')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at max_depth = %i' % max_depth[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}